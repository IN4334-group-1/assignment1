\section{Methodology}
    Now that the research questions have been discussed, the approach for answering those questions can be explained.
    We will start by detailing our sampling method. 
    Thereafter, we introduce the features which we think do have influence on the amount of stars that a repository has.
    Lastly, we discuss the methods for actually constructing a learning model that we can use to predict the amount of stars for a given project.
    \subsection{Sampling Method}
        When we did a first exploration of our data, we found that the distribution of stars per project is extremely right skewed: there are a lot of projects with one or zero stars, while there are much less projects which have a lot of stars, as can be seen in \todo{ADD FIGURE/TABLE}.
        Because of this skewness, the decision was made to use so-called stratified sampling.
        With stratified sampling, we first have to divide the population into homegenous strata. 
        Thereafter, we sample an equal amount of projects from each of these strata; 
        all these samples together form the sample that is being used in the rest of the project.
        
        Each stratum has as characteristic that the amount of stars of the project in that stratum fall within a certain range. 
        The ranges that will be used in this project are: [0, 10], (10, 100], (100, 1000], (1000, +].
        Because the dataset is very large, we can also create a quite large sample:         
        out of each stratum, we will randomly select 500 projects for each stratum. The total size of our sample is thus 2000.
        
        Further, we split up our sample in a training set and a testing set. Out of our sample, we randomly pick 1000 projects which will form our training set. The remainder of the sample will be used as a testing set.
        
        Although we mentioned that the selecting of projects is completely random, it actually is not. In order to reduce bias in our sample, we decided to filter out any project by Google, Microsoft or Apple.
        The way in which they use GitHub is different from most other projects, but they do have a lot of stars, partly due to brand awareness; therefore, they are not included in our sample.
        

        
        
    
        \todo{
            \begin{itemize}
                \item Stratified sampling because of skewness
                \item Discuss strata intervals
                \item Discuss sample size
                \item Discuss items that are excluded from the sample (google/microsoft projects)
                \item Discuss training/testing split
            \end{itemize}
        }
    
    \subsection{Features}
    In order to be able to predict the amount of stars an OSS project will get, a model need to be designed.
    Therefore a number of features is discussed first, which could influence the amount of stars on a project.
    Each of these features fall into one of the high-level groups that are specified: general project characteristics, popularity of developers or organisation, documentation and activity.
    After the features are defined, we can use them in combination with a machine learning algorithm to create the actual prediction model.

    \subsubsection{General project characteristics}
    The first group contains general features belonging to a project. 
    A feature is considered a general project feature if \todo{it cannot be categorized into the other groups}.
    In this section the different features and reasons behind choosing them will be explained.\\
    \begin{LaTeXdescription}
        \item[Name of the project]
        Since the name of the project is one of the first things a user will see, it might be useful to pick something that 
        \item[Number of commits]
        placeholder text 
        \item[Project country of origin]
        \item[Number of commits per developer]
        \item[Total amount of contributers]
        \item[Main programming language]
        \item[How long does the project exists]
    \end{LaTeXdescription}

    %name of the project
    %origin of project ('project owner'->country)
    %#commits
    %#commits/developer
    %amount of contributors on project
    %programming language
    %hoe lang bestaat het project al?

    \subsubsection{Popularity of developers or organisation}
    \todo{intro}\\
    \textbf{Average number of followers per developer}\\
    \textbf{Maximum number of followers per developer}\\
    \textbf{Number of developers in organisation}\\

    %--Developers
    %average #followers/developer
    %max #followers/developer
    %--Organisation
    %#developers
    %average #followers/developer
    %max #followers/developer

    \todo{\subsubsection{Documentation} 
        We also think that the fact that a project is not documented very well or even not documented at all can have influence on the appreciation users show for that project. Unfortunately, this is hard to measure as some projects do have extensive documentation on their own website, while they are not using the GitHub features for documenting the project.
        At the moment of writing, it is also not possible to check if a project has a readme file or a wiki page on GitHub using the earlier discussed dataset. For future research, it might be interesting to involve this feature as well.}
    %readme present?
    %wiki files present?

    \subsubsection{Activity}
    \todo{intro}\\
    \textbf{Number of commits per day}\\
    \textbf{Number of releases}\\
    \textbf{Time between releases}\\
    \textbf{Number of branches}\\

    %#commits/day (follow-up: issue resolution time)
    %#releases 
    %#releases/time
    %#branches

 
    \subsection{Domain}
        Since some project domains are more popular, it is easier to get stars for projects in that domain, simply because more people are interested in that domain.
        Therefore the domain is also considered in the model, to be able to make better predictions as features might weight different across domains.
        Unfortunately, the domain of a project cannot be automatically deduced from the dataset. 
        Therefore, each project in our sample was given a domain manually. Domain is obviously a categorical variable and can take the following values: \todo{decide on possible domains}.

        \todo{
            \begin{itemize}
                \item Discuss high level features
                \item Specify high level features into actual metrics
                \item Discuss adding of the `domain' to filter popular domain areas
            \end{itemize}
        }
    
    
    \subsection{Finding relations}
        Now that the features have been listed, we can try to infer relations between those features. More specifically, we have an independent variable - the amount of stars for a project - and we will try to correlate it with the independent variables - the features listed in the previous section.
        
        The machine learning algorithm that first comes to mind is linear regression. However, some of our features are categorical, e.g. the programming language of a project, which makes it impossible to use linear regression.
        Luckily, there is a variant available which is able to handle categorical variables; this algorithm is called `multiple linear regression'. 
        Initially, this algorithm will be used. Depending on the results, we will try out other algorithms like random forest and naive bayes.
        
        On top of the initial analysis using multiple linear regression, an attempt will be made to finetune our model so that the prediction is as accurate as possible. The step-wise regression algorithm will be used for this task.
    
          \todo{
            \begin{itemize}
                \item Discuss machine learning algorithms (Multiple Linear Regression, Stepwise regression)
            \end{itemize}
        }
