\section{Evaluation}
To make sure the created dataset contains the data we expect, there have been numerous validations on it.
Whenever the data of one of the features was retrieved, we manually checked some of the entries.
This was done by picking ten random samples from the data and looking them up on GitHub to see if the data we have found corresponds with the actual data.
Another point that we checked on, were the outliers in the data.
Whenever a feature contained entries that were much higher or lower than the other ones, we also manually checked them on GitHub to make sure the outliers are correct and not some anomalies in our data.
Some examples of this included a wiki with a single contributor (a bot) and over 100,000 commits and read-only repositories without contributors. 

\subsection{Threats to validity}
When creating the dataset, some issues arose which will be further explained in this section.
Also the steps taken to mitagate the threats, where possible, are described. \\

\subsubsection{Domains}
The projects in the dataset have been classified into different domains.
Since this has been done manually, it can occur that not all projects are classified in the right domains as it introduced subjectiveness.
Some projects also span multiple domains and that makes it hard to categorize it correctly.
Furthermore, the classification has been done only for the main categories.
The projects could have been classified into subcategories, but with a sample size of two thousand projects this would then result in small samples for each of the domains.\\

\subsubsection{Validations}
The data in the GHTorrent dataset is not fully up to date with the latest changes on GitHub.
This made it harder to validate the data that we retrieved, as it differs from the data we find when we look it up on GitHub.
An example of this would be the amount of stars a project has.
If GHTorrent contains data that is a couple of weeks old, the project might have gained or lost some stars in the meantime.
To be able to validate GHTorrent data even though it was not identical to the data currently on GitHub, we introduced a margin for the amounts that we can check.
This means that if a certain user was listed to have $x$ followers in GHTorrent, the user should have a number of  followers in the range of $[x - 0.05 \times x , x + 0.05 \times x]$ on GitHub.
This approach was also applied to the other features, such as stars and commits.\\

\subsubsection{GitHub limitations}
A limitation on GitHub's side is that deletions are not contained in the events that GHTorrent uses.\cite{gousios-2013}
This can introduce inconsistent data, as projects could have been deleted without this data being in the GHTorrent dataset.\\

\subsubsection{Unknown values}
Not all information on GithHub is filled in or can be determined.
Examples of this are the country of the developer that is often left blank, or the main language of the project that cannot be determined.
These values are saved in our dataset as `unknown' and often comprise a large portion of the data.
Because of that, estimations based on for example countries tend to point towards the unknown value.
